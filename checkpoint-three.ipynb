{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "26037d32-2047-4157-81ef-595916bd66a0"
            },
            "source": [
                "# Checkpoint Three: Cleaning Data\n",
                "\n",
                "Now you are ready to clean your data. Before starting coding, provide the link to your dataset below.\n",
                "https://www.kaggle.com/datasets/thedevastator/global-video-game-sales\n",
                "\n",
                "Import the necessary libraries and create your dataframe(s).\n",
                "import pandas as pd\n",
                "import numpy as pd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "e8adef8e-d0f2-4640-a179-5997f11e82ca"
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "df = pd.read_csv(r'vgsales.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "e172475a-c4ee-414a-8367-9965355dbba6"
            },
            "source": [
                "## Missing Data\n",
                "\n",
                "Test your dataset for missing data and handle it as needed. Make notes in the form of code comments as to your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "e1dc66ef-e471-4c27-92e7-ee878c106eba"
            },
            "outputs": [],
            "source": [
                "# checking where my null values lie before taking any action.\n",
                "df.isna().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The dataset is oddly missing 2018-2019, with only a single record for 2020.\n",
                "df['Year'].sort_values().unique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Finding the mean of the year column to use in filling the null values in that column.\n",
                "df['Year'].mean().round()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Filled all null values with the mean of \"Year\" with 2006 so I can convert to an integer later in the cleaning process. \n",
                "df['Year'] = df['Year'].fillna(2006)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The dataset does not have alot of null values in general. Ive decided to let the null values remain since they will not affect\n",
                "# the business question being asked. The columns containing these null values may be dropped later."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "1233f543-e9a0-4f78-96f5-d7536554102e"
            },
            "source": [
                "## Irregular Data\n",
                "\n",
                "Detect outliers in your dataset and handle them as needed. Use code comments to make notes about your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "efed50ae-16f0-471d-98e2-632553a74c12"
            },
            "outputs": [],
            "source": [
                "# Checking all sales columns to pick out possible outliers through the upper quartile and max.\n",
                "df[['NA_Sales','EU_Sales','JP_Sales','Other_Sales','Global_Sales']].describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Any sales below 10K are not counted or are rounded. Since the sales are in fractions, .01 will be 10K."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Created a function to find all the \"outliers\" in each sales column\n",
                "def sales_outlier(x):\n",
                "    up_quart = x.quantile(.75)\n",
                "    outliers = x.loc[x > up_quart * 1.5].agg('sum').round()\n",
                "    return outliers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Counting the \"outliers\" in the NA_Sales column. \n",
                "sales_outlier(df['NA_Sales'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Counting the \"outliers\" in the EU_Sales column.\n",
                "sales_outlier(df['EU_Sales'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Counting the \"outliers\" in the JP_Sales column.\n",
                "sales_outlier(df['JP_Sales'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Counting the \"outliers\" in the Other_Sales column.\n",
                "sales_outlier(df['Other_Sales'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Counting the \"outliers\" in the Global_Sales column.\n",
                "sales_outlier(df['Global_Sales'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "6f5b8ee0-bab3-44bc-958a-67d1e4c0407f"
            },
            "source": [
                "## Unnecessary Data\n",
                "\n",
                "Look for the different types of unnecessary data in your dataset and address it as needed. Make sure to use code comments to illustrate your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "e788a239-2fbf-41de-9bd3-19e52e3b187c"
            },
            "outputs": [],
            "source": [
                "# The \"publisher\" column will not be necessary for the business question being asked, so it will be dropped.\n",
                "# this will also delete the remaining null values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.drop('Publisher',axis = 1)\n",
                "df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "53e0cf94-c68a-4fa0-9849-9505a66bcce6"
            },
            "source": [
                "## Inconsistent Data\n",
                "\n",
                "Check for inconsistent data and address any that arises. As always, use code comments to illustrate your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "e9de6624-812a-43f8-8e20-93b4a49b091f"
            },
            "outputs": [],
            "source": [
                "# Checking for correct datatype for each column. \n",
                "df.dtypes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# I decided to convert the \"Year\" column to an integer to be more uniform. I will use the mean of the \"Year\" column to fill in the\n",
                "# null values so I can convert from a float to an integer.\n",
                "df['Year'].describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Converted the \"Year\" column to an integer dtype to be more uniform. \n",
                "df['Year'] = df['Year'].astype(int)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# checking the data types here I can verify that the column is now an integer.\n",
                "df.dtypes\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Checking the \"Genre\" column for any inconsistent genre names. \n",
                "df['Genre'].unique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Checking the \"Platform\" column for any inconsistent console names.\n",
                "df['Platform'].unique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# confirming data has no nulls and is properly cleaned before creating new csv.\n",
                "df.isna().sum()\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creating a new csv called \"cleaned_vgsales\" to use for task 4.\n",
                "df.to_csv('cleaned_vgsales')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# reading the csv and producing a sample to make sure everything works as it should.\n",
                "cleaned_df = pd.read_csv(r'cleaned_vgsales')\n",
                "cleaned_df.sample(20)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# double checking that there is no nulls left after cleaning. \n",
                "cleaned_df.isna().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "dedc0bfe-17d0-40b2-914f-2ddb54f9ce0d"
            },
            "source": [
                "## Summarize Your Results\n",
                "\n",
                "Make note of your answers to the following questions.\n",
                "\n",
                "1. Did you find all four types of dirty data in your dataset?\n",
                "A. No, I found 3 different types of dirty data however my outliers will need be be included in the dataset since they're mostly highly popular games.\n",
                "2. Did the process of cleaning your data give you new insights into your dataset?\n",
                "A. Yes, It really showed how many games dont break through the market and retain small amounts of sales.\n",
                "3. Is there anything you would like to make note of when it comes to manipulating the data and making visualizations?\n",
                "A. Yes, I think it would be very useful to convert the fractional sales into whole dollars to make it easier to read and understand."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
